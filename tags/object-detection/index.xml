<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Object Detection on Shahed Anzarus Sabab</title>
    <link>https://shahedsabab.github.io/shahed_portfolio/tags/object-detection/</link>
    <description>Recent content in Object Detection on Shahed Anzarus Sabab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Apr 2017 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="https://shahedsabab.github.io/shahed_portfolio/tags/object-detection/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>License Number Extraction - YOLO v4, Vision API (GCP)</title>
      <link>https://shahedsabab.github.io/shahed_portfolio/post/project-licenseplate/</link>
      <pubDate>Thu, 06 Apr 2017 10:58:08 -0400</pubDate>
      
      <guid>https://shahedsabab.github.io/shahed_portfolio/post/project-licenseplate/</guid>
      <description>The objective is to extract the registration/license plate number from different vehicle images. The task is divided into two parts. First, detect the possible ROI(region of interest) - in this case, it is the license plate of vehicles. Second, extract the letters and numbers from the detected region. To separate ROI from the images, object detection model - YOLO v4 is used. YOLO v4 (You only look once) is a family of one-stage object detectors that are fast (i.</description>
    </item>
    
    <item>
      <title>Eye Pointer: A system designed for amputees - Haar Cascade, OpenCV, C#</title>
      <link>https://shahedsabab.github.io/shahed_portfolio/post/project-eyepointer/</link>
      <pubDate>Sun, 19 Mar 2017 11:00:59 -0400</pubDate>
      
      <guid>https://shahedsabab.github.io/shahed_portfolio/post/project-eyepointer/</guid>
      <description>The objective of this project is to develop a system for physically impaired people who do not have a pair of working hands. The system provides different functionalities to the users: navigate computers using head movements, eye blink for clicking, different head gestures to read documents, and watch multimedia. The system is developed using C#. The head movement is tracked using EmguCV (OpenCV wrapper) and some heuristic calculations. Blink detection is performed using haarcascade of eyes.</description>
    </item>
    
    <item>
      <title>Hand Swifter: Control computer with hand gestures - Haar Cascade, OpenCV, C#</title>
      <link>https://shahedsabab.github.io/shahed_portfolio/post/project-handswifter/</link>
      <pubDate>Tue, 14 Mar 2017 11:00:59 -0400</pubDate>
      
      <guid>https://shahedsabab.github.io/shahed_portfolio/post/project-handswifter/</guid>
      <description>A system to replace the traditional mouse and keyboard that only uses hand gestures to control computers. This system focuses on navigating computers, reading documents and controlling multimedia like videos, pictures. This multimodal system uses a leap motion device and a webcam to capture hand movements and different gestures.
 Real-time tracking of hand movement. (haarcascade, Viola-Jones)  Implements the Kalman filter for smoothing.  Captures hand gesture with leap motion device.</description>
    </item>
    
  </channel>
</rss>